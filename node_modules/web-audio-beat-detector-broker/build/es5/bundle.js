(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('@babel/runtime/helpers/defineProperty'), require('@babel/runtime/helpers/typeof'), require('@babel/runtime/helpers/asyncToGenerator'), require('@babel/runtime/regenerator'), require('broker-factory'), require('standardized-audio-context')) :
    typeof define === 'function' && define.amd ? define(['exports', '@babel/runtime/helpers/defineProperty', '@babel/runtime/helpers/typeof', '@babel/runtime/helpers/asyncToGenerator', '@babel/runtime/regenerator', 'broker-factory', 'standardized-audio-context'], factory) :
    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.webAudioBeatDetectorBroker = {}, global._defineProperty, global._typeof, global._asyncToGenerator, global._regeneratorRuntime, global.brokerFactory, global.standardizedAudioContext));
})(this, (function (exports, _defineProperty, _typeof, _asyncToGenerator, _regeneratorRuntime, brokerFactory, standardizedAudioContext) { 'use strict';

    var render = function render(audioBuffer, offset, duration) {
      var offlineAudioContext = new standardizedAudioContext.OfflineAudioContext(audioBuffer.numberOfChannels, Math.round(duration * audioBuffer.sampleRate), audioBuffer.sampleRate);
      var biquadFilter = offlineAudioContext.createBiquadFilter();
      var bufferSourceNode = offlineAudioContext.createBufferSource();
      biquadFilter.frequency.value = 240;
      biquadFilter.type = 'lowpass';
      bufferSourceNode.buffer = audioBuffer;
      bufferSourceNode.connect(biquadFilter).connect(offlineAudioContext.destination);
      bufferSourceNode.start(0, offset, duration);
      return offlineAudioContext.startRendering().then(function (renderedBuffer) {
        var channelData = renderedBuffer.getChannelData(0);
        var sampleRate = renderedBuffer.sampleRate;
        return {
          channelData: channelData,
          sampleRate: sampleRate
        };
      });
    };

    function ownKeys(e, r) { var t = Object.keys(e); if (Object.getOwnPropertySymbols) { var o = Object.getOwnPropertySymbols(e); r && (o = o.filter(function (r) { return Object.getOwnPropertyDescriptor(e, r).enumerable; })), t.push.apply(t, o); } return t; }
    function _objectSpread(e) { for (var r = 1; r < arguments.length; r++) { var t = null != arguments[r] ? arguments[r] : {}; r % 2 ? ownKeys(Object(t), true).forEach(function (r) { _defineProperty(e, r, t[r]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) { Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r)); }); } return e; }
    var wrap = brokerFactory.createBroker({
      analyze: function analyze(_ref) {
        var call = _ref.call;
        return /*#__PURE__*/_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
          var _a,
            _len,
            args,
            _key,
            audioBuffer,
            offsetOrTempoSettings,
            durationOrTempoSettings,
            offset,
            duration,
            _yield$render,
            channelData,
            sampleRate,
            tempoSettings,
            _args = arguments;
          return _regeneratorRuntime.wrap(function _callee$(_context) {
            while (1) switch (_context.prev = _context.next) {
              case 0:
                for (_len = _args.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
                  args[_key] = _args[_key];
                }
                audioBuffer = args[0], offsetOrTempoSettings = args[1], durationOrTempoSettings = args[2];
                offset = typeof offsetOrTempoSettings === 'number' ? offsetOrTempoSettings : 0;
                duration = typeof durationOrTempoSettings === 'number' ? durationOrTempoSettings : audioBuffer.duration - offset;
                _context.next = 6;
                return render(audioBuffer, offset, duration);
              case 6:
                _yield$render = _context.sent;
                channelData = _yield$render.channelData;
                sampleRate = _yield$render.sampleRate;
                tempoSettings = _typeof(offsetOrTempoSettings) === 'object' ? offsetOrTempoSettings : _typeof(durationOrTempoSettings) === 'object' ? durationOrTempoSettings : (_a = args[3]) !== null && _a !== void 0 ? _a : null;
                return _context.abrupt("return", call('analyze', _objectSpread({
                  channelData: channelData,
                  sampleRate: sampleRate
                }, tempoSettings === null ? tempoSettings : {
                  tempoSettings: tempoSettings
                }), [channelData.buffer]));
              case 11:
              case "end":
                return _context.stop();
            }
          }, _callee);
        }));
      },
      guess: function guess(_ref3) {
        var call = _ref3.call;
        return /*#__PURE__*/_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {
          var _a,
            _len2,
            args,
            _key2,
            audioBuffer,
            offsetOrTempoSettings,
            durationOrTempoSettings,
            offset,
            duration,
            _yield$render2,
            channelData,
            sampleRate,
            tempoSettings,
            _args2 = arguments;
          return _regeneratorRuntime.wrap(function _callee2$(_context2) {
            while (1) switch (_context2.prev = _context2.next) {
              case 0:
                for (_len2 = _args2.length, args = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {
                  args[_key2] = _args2[_key2];
                }
                audioBuffer = args[0], offsetOrTempoSettings = args[1], durationOrTempoSettings = args[2];
                offset = typeof offsetOrTempoSettings === 'number' ? offsetOrTempoSettings : 0;
                duration = typeof durationOrTempoSettings === 'number' ? durationOrTempoSettings : audioBuffer.duration - offset;
                _context2.next = 6;
                return render(audioBuffer, offset, duration);
              case 6:
                _yield$render2 = _context2.sent;
                channelData = _yield$render2.channelData;
                sampleRate = _yield$render2.sampleRate;
                tempoSettings = _typeof(offsetOrTempoSettings) === 'object' ? offsetOrTempoSettings : _typeof(durationOrTempoSettings) === 'object' ? durationOrTempoSettings : (_a = args[3]) !== null && _a !== void 0 ? _a : null;
                return _context2.abrupt("return", call('guess', _objectSpread({
                  channelData: channelData,
                  sampleRate: sampleRate
                }, tempoSettings === null ? tempoSettings : {
                  tempoSettings: tempoSettings
                }), [channelData.buffer]));
              case 11:
              case "end":
                return _context2.stop();
            }
          }, _callee2);
        }));
      }
    });
    var load = function load(url) {
      var worker = new Worker(url);
      return wrap(worker);
    };

    Object.defineProperty(exports, "isSupported", {
        enumerable: true,
        get: function () { return standardizedAudioContext.isSupported; }
    });
    exports.load = load;
    exports.wrap = wrap;

}));
